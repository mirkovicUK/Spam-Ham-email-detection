{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#1.1 Import libraries\n","import pandas as pd\n","import numpy as np\n","import xgboost as xgb\n","from   sklearn.model_selection import train_test_split\n","from   sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n","from   sklearn.model_selection import GridSearchCV # use forcross validation\n","from   sklearn.metrics import plot_confusion_matrix\n","from   sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from   sklearn.metrics import accuracy_score\n","import matplotlib.pyplot as plt\n","from   sklearn.feature_extraction.text import CountVectorizer\n","import seaborn as sns\n","import sys\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#1.2 Import and sort data\n","\n","df = pd.read_csv(\"spam.csv\")\n","df.drop([\"v3\",\"v4\", \"v5\"], axis=1, inplace=True)\n","# check ham column\n","df[\"spam\"].unique()\n","# check for missing val \n","len(df.loc[df[\"spam\"] == \" \"]) \n","len(df.loc[df[\"email\"] == \" \"])\n","\n","df[\"spam\"].replace(\"spam\",1 , inplace=True)\n","df[\"spam\"].replace(\"ham\",0 , inplace=True)\n","\n","y = df[\"spam\"].copy()\n","X = df[\"email\"].copy()\n","df.head()\n","X.head()\n","y.head()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#1.3 Encoding\n","#count words and frequency\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(X)\n","column_names = vectorizer.get_feature_names_out()\n","\n","#convert X back to panda object for visualization\n","X = pd.DataFrame(X.toarray())\n","X.columns = column_names\n","X.head()\n","X.shape\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#1.4 Looking at data -> high disbalans \n","# Check procentage of ham in email\n","sum(y) / len(y) # ham 87% spam 13%\n","sum(y)\n","len(y) - sum(y)\n","#procentage vizualization\n","sns.set()\n","sns.countplot(data=df, x=y).set_title(\"Ham --------- Spam \", fontweight = \"bold\")\n","#plt.show()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#1.5Building preliminary GXBoost model \n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25, stratify=y)\n","\n","clf_xgb = xgb.XGBClassifier(objective=\"binary:logistic\", \n","                                early_stopping_rounds=10,\n","                                eval_metric=\"auc\", \n","                                seed=42\n","                            )\n","clf_xgb.fit(X_train, y_train, verbose=False, eval_set=[(X_test, y_test)])\n","print(\"Best Iteration no: {}\".format(clf_xgb.get_booster().best_iteration))\n","print(\"Best Iteration score: {}\".format(clf_xgb.get_booster().best_score))\n","\n","##############################################\n","#double check / different metrics\n","##############################################\n","#Predict = clf_xgb.predict(X_test)\n","#Score = accuracy_score(y_test, Predict)\n","#print(\"THIS IS DOUBLE CHECK OF FIT: \",end=\"\")\n","#print(Score)\n","##############################################\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#1.6 Print Confusion Matrix\n","plot_confusion_matrix(clf_xgb,\n","                    X_test,\n","                    y_test,\n","                    values_format=\"d\",\n","                    display_labels=[\"Ham\", \"Spam\"])\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#1.7 Measuring performance on new data set and printing confusin matrix\n","\n","#read in new data\n","df_new = pd.read_csv(\"test_data/spam_ham1.csv\")\n","df_new.head()\n","#Check for missing values\n","len(df_new.loc[df_new[\"spam\"] == \" \"]) \n","len(df_new.loc[df_new[\"email\"] == \" \"])\n","\n","y_new = df_new[\"spam\"].copy()\n","y_new.unique()\n","X_new = df_new[\"email\"].copy()\n","y_new.head()\n","X_new.head()\n","\n","# Check percentage of spam ham in data set\n","sum(y_new) / len(y_new) # new data set contains 24% of spam emails \n","\n","# count words and frequency\n","X_new = vectorizer.transform(X_new)\n","X_new = pd.DataFrame(X_new.toarray())\n","#Confirm New data set b4 feeding to clf_xgb\n","X_new.shape\n","y_new.shape\n","\n","#prediction\n","y_predict = clf_xgb.predict(X_new)\n","score=accuracy_score(y_new, y_predict)\n","print(\"Acuracy score on same model on new data set is: \",end=\"\")\n","print(score)\n","\n","# confusion matrix\n","plot_confusion_matrix(clf_xgb,\n","                    X_new,\n","                    y_new,\n","                    values_format=\"d\",\n","                    display_labels=[\"Ham\", \"Spam\"])\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#1.8 Optimize xgBoost parameters using Cross Validation and GridSearch()\n","\n","param_grid = {\"max_depth\" : [3], \n","            \"learning_rate\" : [0.75],\n","            \"gamma\" : [0.01, 0.05, 0.01, 0.10, 0.15, 0.25 ], \n","            \"reg_lambda\" : [3.0], \n","            \"scale_pos_weight\" : [0.5] \n","            }\n","\n","\n","######################################################################################################\n","# CROSs VALIDATION  GridSearchCV optimization comented out for optimal program flow                 ##\n","# Optimization si done on initial data set                                                          ##\n","# This optimization is for   CountVectorizer() no parameters                                        ##                                     \n","################################################################################################## ###\n","#optimal_params = GridSearchCV(estimator=xgb.XGBClassifier(objective=\"binary:logistic\", \n","#                                                        seed=42, \n","#                                                        subsample=0.9, \n","#                                                        colsample_bytree=0.5, \n","#                                                        early_stopping_rounds=10, \n","#                                                        eval_metric=\"auc\"),\n","#                            param_grid=param_grid,\n","#                            scoring=\"roc_auc\",\n","#                            verbose=2, \n","#                            n_jobs=10,\n","#                            cv = 3)                     \n","#optimal_params.fit(X_train, y_train, verbose=True, eval_set=[(X_test, y_test)])\n","#print(optimal_params.best_params_)\n","#sys.exit()\n","######################################################################################################################################################################\n","#rounds of optimization and output \n","######################################################################################################################################################################\n","#Round1:param_grid = {\"max_depth\" : [3, 4, 5], \"learning_rate\" : [0.05, 0.1, 0.25],\"gamma\" : [0, 0.25, 1.0],\"reg_lambda\" : [1, 5, 10], \"scale_pos_weight\" : [2, 3, 4]}\n","# output cv = {'gamma': 1.0, 'learning_rate': 0.25, 'max_depth': 4, 'reg_lambda': 1, 'scale_pos_weight': 2}\n","#Round2:{\"max_depth\" : [3, 4, 5], \"learning_rate\" : [0.05, 0.1, 0.25],\"gamma\" : [1, 2, 3],\"reg_lambda\" : [1, 5, 10], scale_pos_weight\" : [2, 3, 4]}\n","# output cv={'gamma': 2, 'learning_rate': 0.5, 'max_depth': 4, 'reg_lambda': 1.0, 'scale_pos_weight': 3}\n","#Round3: param_grid = {\"max_depth\" : [4], \"learning_rate\" : [0.25, 0.50, 0.75],\"gamma\" : [2,5,10], \"reg_lambda\" : [1.0, 3.0, 5.0], \"scale_pos_weight\" : [3,5] }\n","# output: {'gamma': 2, 'learning_rate': 0.5, 'max_depth': 4, 'reg_lambda': 1.0, 'scale_pos_weight': 3}\n","#etc...\n","#final paramiters for new model :{'gamma': 1.5, 'learning_rate': 0.5, 'max_depth': 4, 'reg_lambda': 1.0, }\n","#####################################################################################################################################################################\n","#####################################################################################################################################################################\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#1.9 Building optimized GXBoost Model\n","clf_xgb = xgb.XGBClassifier(seed=42, \n","                            objective=\"binary:logistic\",\n","                            gamma=1.5,\n","                            learning_rate=0.5,\n","                            max_depth=4,\n","                            reg_lambda=1, \n","                            scale_pos_weight=0.1, \n","                            early_stopping_rounds=10, \n","                            eval_metric=\"auc\")\n","clf_xgb.fit(X_train, y_train, verbose=False, eval_set=[(X_test, y_test)])\n","\n","#prediction for original data set\n","y_pred = clf_xgb.predict(X_test)\n","Score_one = accuracy_score(y_true=y_test, y_pred=y_pred)\n","print(\"OPTIMIZED MODEL original data set accuracy: \",end=\"\")\n","print(Score_one)\n","#confusion matrix Original data\n","plot_confusion_matrix(clf_xgb,\n","                    X_test,\n","                    y_test,\n","                    values_format=\"d\",\n","                    display_labels=[\"Ham\", \"Spam\"])\n","\n","#Prediction for new dataset\n","y_pred_new = clf_xgb.predict(X_new)\n","Score_two = accuracy_score(y_true=y_new, y_pred=y_pred_new)\n","print(\"OPTIMIZED MODEL NEW dataset accuracy: \",end=\"\")\n","print(Score_two)\n","#confusion matrix new data\n","plot_confusion_matrix(clf_xgb,\n","                    X_new,\n","                    y_new,\n","                    values_format=\"d\",\n","                    display_labels=[\"Ham\", \"Spam\"])"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}